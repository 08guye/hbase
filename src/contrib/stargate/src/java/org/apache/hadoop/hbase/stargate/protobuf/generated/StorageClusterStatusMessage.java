// Generated by the protocol buffer compiler.  DO NOT EDIT!

package org.apache.hadoop.hbase.stargate.protobuf.generated;

public final class StorageClusterStatusMessage {
  private StorageClusterStatusMessage() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public static final class StorageClusterStatus extends
      com.google.protobuf.GeneratedMessage {
    // Use StorageClusterStatus.newBuilder() to construct.
    private StorageClusterStatus() {}
    
    private static final StorageClusterStatus defaultInstance = new StorageClusterStatus();
    public static StorageClusterStatus getDefaultInstance() {
      return defaultInstance;
    }
    
    public StorageClusterStatus getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_descriptor;
    }
    
    @Override
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_fieldAccessorTable;
    }
    
    public static final class Node extends
        com.google.protobuf.GeneratedMessage {
      // Use Node.newBuilder() to construct.
      private Node() {}
      
      private static final Node defaultInstance = new Node();
      public static Node getDefaultInstance() {
        return defaultInstance;
      }
      
      public Node getDefaultInstanceForType() {
        return defaultInstance;
      }
      
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_descriptor;
      }
      
      @Override
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable;
      }
      
      // required string name = 1;
      public static final int NAME_FIELD_NUMBER = 1;
      private boolean hasName;
      private java.lang.String name_ = "";
      public boolean hasName() { return hasName; }
      public java.lang.String getName() { return name_; }
      
      // optional int64 startCode = 4;
      public static final int STARTCODE_FIELD_NUMBER = 4;
      private boolean hasStartCode;
      private long startCode_ = 0L;
      public boolean hasStartCode() { return hasStartCode; }
      public long getStartCode() { return startCode_; }
      
      // optional int32 requests = 2;
      public static final int REQUESTS_FIELD_NUMBER = 2;
      private boolean hasRequests;
      private int requests_ = 0;
      public boolean hasRequests() { return hasRequests; }
      public int getRequests() { return requests_; }
      
      // repeated bytes regions = 3;
      public static final int REGIONS_FIELD_NUMBER = 3;
      private java.util.List<com.google.protobuf.ByteString> regions_ =
        java.util.Collections.emptyList();
      public java.util.List<com.google.protobuf.ByteString> getRegionsList() {
        return regions_;
      }
      public int getRegionsCount() { return regions_.size(); }
      public com.google.protobuf.ByteString getRegions(int index) {
        return regions_.get(index);
      }
      
      @Override
      public final boolean isInitialized() {
        if (!hasName) return false;
        return true;
      }
      
      @Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (hasName()) {
          output.writeString(1, getName());
        }
        if (hasRequests()) {
          output.writeInt32(2, getRequests());
        }
        for (com.google.protobuf.ByteString element : getRegionsList()) {
          output.writeBytes(3, element);
        }
        if (hasStartCode()) {
          output.writeInt64(4, getStartCode());
        }
        getUnknownFields().writeTo(output);
      }
      
      private int memoizedSerializedSize = -1;
      @Override
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;
      
        size = 0;
        if (hasName()) {
          size += com.google.protobuf.CodedOutputStream
            .computeStringSize(1, getName());
        }
        if (hasRequests()) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(2, getRequests());
        }
        {
          int dataSize = 0;
          for (com.google.protobuf.ByteString element : getRegionsList()) {
            dataSize += com.google.protobuf.CodedOutputStream
              .computeBytesSizeNoTag(element);
          }
          size += dataSize;
          size += 1 * getRegionsList().size();
        }
        if (hasStartCode()) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(4, getStartCode());
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }
      
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return newBuilder().mergeDelimitedFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeDelimitedFrom(input, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      
      public static Builder newBuilder() { return new Builder(); }
      public Builder newBuilderForType() { return new Builder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node prototype) {
        return new Builder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }
      
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder> {
        // Construct using org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.newBuilder()
        private Builder() {}
        
        org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node result = new org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node();
        
        @Override
        protected org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node internalGetResult() {
          return result;
        }
        
        @Override
        public Builder clear() {
          result = new org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node();
          return this;
        }
        
        @Override
        public Builder clone() {
          return new Builder().mergeFrom(result);
        }
        
        @Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDescriptor();
        }
        
        public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance();
        }
        
        public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node build() {
          if (result != null && !isInitialized()) {
            throw new com.google.protobuf.UninitializedMessageException(
              result);
          }
          return buildPartial();
        }
        
        private org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node buildParsed()
            throws com.google.protobuf.InvalidProtocolBufferException {
          if (!isInitialized()) {
            throw new com.google.protobuf.UninitializedMessageException(
              result).asInvalidProtocolBufferException();
          }
          return buildPartial();
        }
        
        public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node buildPartial() {
          if (result == null) {
            throw new IllegalStateException(
              "build() has already been called on this Builder.");  }
          if (result.regions_ != java.util.Collections.EMPTY_LIST) {
            result.regions_ =
              java.util.Collections.unmodifiableList(result.regions_);
          }
          org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node returnMe = result;
          result = null;
          return returnMe;
        }
        
        @Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node) {
            return mergeFrom((org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }
        
        public Builder mergeFrom(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node other) {
          if (other == org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.getDefaultInstance()) return this;
          if (other.hasName()) {
            setName(other.getName());
          }
          if (other.hasStartCode()) {
            setStartCode(other.getStartCode());
          }
          if (other.hasRequests()) {
            setRequests(other.getRequests());
          }
          if (!other.regions_.isEmpty()) {
            if (result.regions_.isEmpty()) {
              result.regions_ = new java.util.ArrayList<com.google.protobuf.ByteString>();
            }
            result.regions_.addAll(other.regions_);
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }
        
        @Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return mergeFrom(input,
            com.google.protobuf.ExtensionRegistry.getEmptyRegistry());
        }
        
        @Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistry extensionRegistry)
            throws java.io.IOException {
          com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder(
              this.getUnknownFields());
          while (true) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                this.setUnknownFields(unknownFields.build());
                return this;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  this.setUnknownFields(unknownFields.build());
                  return this;
                }
                break;
              }
              case 10: {
                setName(input.readString());
                break;
              }
              case 16: {
                setRequests(input.readInt32());
                break;
              }
              case 26: {
                addRegions(input.readBytes());
                break;
              }
              case 32: {
                setStartCode(input.readInt64());
                break;
              }
            }
          }
        }
        
        
        // required string name = 1;
        public boolean hasName() {
          return result.hasName();
        }
        public java.lang.String getName() {
          return result.getName();
        }
        public Builder setName(java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  result.hasName = true;
          result.name_ = value;
          return this;
        }
        public Builder clearName() {
          result.hasName = false;
          result.name_ = "";
          return this;
        }
        
        // optional int64 startCode = 4;
        public boolean hasStartCode() {
          return result.hasStartCode();
        }
        public long getStartCode() {
          return result.getStartCode();
        }
        public Builder setStartCode(long value) {
          result.hasStartCode = true;
          result.startCode_ = value;
          return this;
        }
        public Builder clearStartCode() {
          result.hasStartCode = false;
          result.startCode_ = 0L;
          return this;
        }
        
        // optional int32 requests = 2;
        public boolean hasRequests() {
          return result.hasRequests();
        }
        public int getRequests() {
          return result.getRequests();
        }
        public Builder setRequests(int value) {
          result.hasRequests = true;
          result.requests_ = value;
          return this;
        }
        public Builder clearRequests() {
          result.hasRequests = false;
          result.requests_ = 0;
          return this;
        }
        
        // repeated bytes regions = 3;
        public java.util.List<com.google.protobuf.ByteString> getRegionsList() {
          return java.util.Collections.unmodifiableList(result.regions_);
        }
        public int getRegionsCount() {
          return result.getRegionsCount();
        }
        public com.google.protobuf.ByteString getRegions(int index) {
          return result.getRegions(index);
        }
        public Builder setRegions(int index, com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  result.regions_.set(index, value);
          return this;
        }
        public Builder addRegions(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  if (result.regions_.isEmpty()) {
            result.regions_ = new java.util.ArrayList<com.google.protobuf.ByteString>();
          }
          result.regions_.add(value);
          return this;
        }
        public Builder addAllRegions(
            java.lang.Iterable<? extends com.google.protobuf.ByteString> values) {
          if (result.regions_.isEmpty()) {
            result.regions_ = new java.util.ArrayList<com.google.protobuf.ByteString>();
          }
          super.addAll(values, result.regions_);
          return this;
        }
        public Builder clearRegions() {
          result.regions_ = java.util.Collections.emptyList();
          return this;
        }
      }
      
      static {
        org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.getDescriptor();
      }
    }
    
    // repeated .org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;
    public static final int LIVENODES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> liveNodes_ =
      java.util.Collections.emptyList();
    public java.util.List<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> getLiveNodesList() {
      return liveNodes_;
    }
    public int getLiveNodesCount() { return liveNodes_.size(); }
    public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getLiveNodes(int index) {
      return liveNodes_.get(index);
    }
    
    // repeated string deadNodes = 2;
    public static final int DEADNODES_FIELD_NUMBER = 2;
    private java.util.List<java.lang.String> deadNodes_ =
      java.util.Collections.emptyList();
    public java.util.List<java.lang.String> getDeadNodesList() {
      return deadNodes_;
    }
    public int getDeadNodesCount() { return deadNodes_.size(); }
    public java.lang.String getDeadNodes(int index) {
      return deadNodes_.get(index);
    }
    
    // optional int32 regions = 3;
    public static final int REGIONS_FIELD_NUMBER = 3;
    private boolean hasRegions;
    private int regions_ = 0;
    public boolean hasRegions() { return hasRegions; }
    public int getRegions() { return regions_; }
    
    // optional int32 requests = 4;
    public static final int REQUESTS_FIELD_NUMBER = 4;
    private boolean hasRequests;
    private int requests_ = 0;
    public boolean hasRequests() { return hasRequests; }
    public int getRequests() { return requests_; }
    
    // optional double averageLoad = 5;
    public static final int AVERAGELOAD_FIELD_NUMBER = 5;
    private boolean hasAverageLoad;
    private double averageLoad_ = 0D;
    public boolean hasAverageLoad() { return hasAverageLoad; }
    public double getAverageLoad() { return averageLoad_; }
    
    @Override
    public final boolean isInitialized() {
      for (org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node element : getLiveNodesList()) {
        if (!element.isInitialized()) return false;
      }
      return true;
    }
    
    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node element : getLiveNodesList()) {
        output.writeMessage(1, element);
      }
      for (java.lang.String element : getDeadNodesList()) {
        output.writeString(2, element);
      }
      if (hasRegions()) {
        output.writeInt32(3, getRegions());
      }
      if (hasRequests()) {
        output.writeInt32(4, getRequests());
      }
      if (hasAverageLoad()) {
        output.writeDouble(5, getAverageLoad());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    @Override
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node element : getLiveNodesList()) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, element);
      }
      {
        int dataSize = 0;
        for (java.lang.String element : getDeadNodesList()) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeStringSizeNoTag(element);
        }
        size += dataSize;
        size += 1 * getDeadNodesList().size();
      }
      if (hasRegions()) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, getRegions());
      }
      if (hasRequests()) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, getRequests());
      }
      if (hasAverageLoad()) {
        size += com.google.protobuf.CodedOutputStream
          .computeDoubleSize(5, getAverageLoad());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistry extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistry extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistry extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeDelimitedFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistry extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeDelimitedFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistry extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return new Builder(); }
    public Builder newBuilderForType() { return new Builder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus prototype) {
      return new Builder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder> {
      // Construct using org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.newBuilder()
      private Builder() {}
      
      org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus result = new org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus();
      
      @Override
      protected org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus internalGetResult() {
        return result;
      }
      
      @Override
      public Builder clear() {
        result = new org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus();
        return this;
      }
      
      @Override
      public Builder clone() {
        return new Builder().mergeFrom(result);
      }
      
      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus build() {
        if (result != null && !isInitialized()) {
          throw new com.google.protobuf.UninitializedMessageException(
            result);
        }
        return buildPartial();
      }
      
      private org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        if (!isInitialized()) {
          throw new com.google.protobuf.UninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return buildPartial();
      }
      
      public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus buildPartial() {
        if (result == null) {
          throw new IllegalStateException(
            "build() has already been called on this Builder.");  }
        if (result.liveNodes_ != java.util.Collections.EMPTY_LIST) {
          result.liveNodes_ =
            java.util.Collections.unmodifiableList(result.liveNodes_);
        }
        if (result.deadNodes_ != java.util.Collections.EMPTY_LIST) {
          result.deadNodes_ =
            java.util.Collections.unmodifiableList(result.deadNodes_);
        }
        org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus returnMe = result;
        result = null;
        return returnMe;
      }
      
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus) {
          return mergeFrom((org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus other) {
        if (other == org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.getDefaultInstance()) return this;
        if (!other.liveNodes_.isEmpty()) {
          if (result.liveNodes_.isEmpty()) {
            result.liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>();
          }
          result.liveNodes_.addAll(other.liveNodes_);
        }
        if (!other.deadNodes_.isEmpty()) {
          if (result.deadNodes_.isEmpty()) {
            result.deadNodes_ = new java.util.ArrayList<java.lang.String>();
          }
          result.deadNodes_.addAll(other.deadNodes_);
        }
        if (other.hasRegions()) {
          setRegions(other.getRegions());
        }
        if (other.hasRequests()) {
          setRequests(other.getRequests());
        }
        if (other.hasAverageLoad()) {
          setAverageLoad(other.getAverageLoad());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return mergeFrom(input,
          com.google.protobuf.ExtensionRegistry.getEmptyRegistry());
      }
      
      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistry extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder subBuilder = org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addLiveNodes(subBuilder.buildPartial());
              break;
            }
            case 18: {
              addDeadNodes(input.readString());
              break;
            }
            case 24: {
              setRegions(input.readInt32());
              break;
            }
            case 32: {
              setRequests(input.readInt32());
              break;
            }
            case 41: {
              setAverageLoad(input.readDouble());
              break;
            }
          }
        }
      }
      
      
      // repeated .org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatus.Node liveNodes = 1;
      public java.util.List<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> getLiveNodesList() {
        return java.util.Collections.unmodifiableList(result.liveNodes_);
      }
      public int getLiveNodesCount() {
        return result.getLiveNodesCount();
      }
      public org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node getLiveNodes(int index) {
        return result.getLiveNodes(index);
      }
      public Builder setLiveNodes(int index, org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node value) {
        if (value == null) {
          throw new NullPointerException();
        }
        result.liveNodes_.set(index, value);
        return this;
      }
      public Builder setLiveNodes(int index, org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder builderForValue) {
        result.liveNodes_.set(index, builderForValue.build());
        return this;
      }
      public Builder addLiveNodes(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node value) {
        if (value == null) {
          throw new NullPointerException();
        }
        if (result.liveNodes_.isEmpty()) {
          result.liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>();
        }
        result.liveNodes_.add(value);
        return this;
      }
      public Builder addLiveNodes(org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder builderForValue) {
        if (result.liveNodes_.isEmpty()) {
          result.liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>();
        }
        result.liveNodes_.add(builderForValue.build());
        return this;
      }
      public Builder addAllLiveNodes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node> values) {
        if (result.liveNodes_.isEmpty()) {
          result.liveNodes_ = new java.util.ArrayList<org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node>();
        }
        super.addAll(values, result.liveNodes_);
        return this;
      }
      public Builder clearLiveNodes() {
        result.liveNodes_ = java.util.Collections.emptyList();
        return this;
      }
      
      // repeated string deadNodes = 2;
      public java.util.List<java.lang.String> getDeadNodesList() {
        return java.util.Collections.unmodifiableList(result.deadNodes_);
      }
      public int getDeadNodesCount() {
        return result.getDeadNodesCount();
      }
      public java.lang.String getDeadNodes(int index) {
        return result.getDeadNodes(index);
      }
      public Builder setDeadNodes(int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  result.deadNodes_.set(index, value);
        return this;
      }
      public Builder addDeadNodes(java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  if (result.deadNodes_.isEmpty()) {
          result.deadNodes_ = new java.util.ArrayList<java.lang.String>();
        }
        result.deadNodes_.add(value);
        return this;
      }
      public Builder addAllDeadNodes(
          java.lang.Iterable<? extends java.lang.String> values) {
        if (result.deadNodes_.isEmpty()) {
          result.deadNodes_ = new java.util.ArrayList<java.lang.String>();
        }
        super.addAll(values, result.deadNodes_);
        return this;
      }
      public Builder clearDeadNodes() {
        result.deadNodes_ = java.util.Collections.emptyList();
        return this;
      }
      
      // optional int32 regions = 3;
      public boolean hasRegions() {
        return result.hasRegions();
      }
      public int getRegions() {
        return result.getRegions();
      }
      public Builder setRegions(int value) {
        result.hasRegions = true;
        result.regions_ = value;
        return this;
      }
      public Builder clearRegions() {
        result.hasRegions = false;
        result.regions_ = 0;
        return this;
      }
      
      // optional int32 requests = 4;
      public boolean hasRequests() {
        return result.hasRequests();
      }
      public int getRequests() {
        return result.getRequests();
      }
      public Builder setRequests(int value) {
        result.hasRequests = true;
        result.requests_ = value;
        return this;
      }
      public Builder clearRequests() {
        result.hasRequests = false;
        result.requests_ = 0;
        return this;
      }
      
      // optional double averageLoad = 5;
      public boolean hasAverageLoad() {
        return result.hasAverageLoad();
      }
      public double getAverageLoad() {
        return result.getAverageLoad();
      }
      public Builder setAverageLoad(double value) {
        result.hasAverageLoad = true;
        result.averageLoad_ = value;
        return this;
      }
      public Builder clearAverageLoad() {
        result.hasAverageLoad = false;
        result.averageLoad_ = 0D;
        return this;
      }
    }
    
    static {
      org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.getDescriptor();
    }
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String descriptorData =
      "\n!StorageClusterStatusMessage.proto\0223org" +
      ".apache.hadoop.hbase.stargate.protobuf.g" +
      "enerated\"\220\002\n\024StorageClusterStatus\022a\n\tliv" +
      "eNodes\030\001 \003(\0132N.org.apache.hadoop.hbase.s" +
      "targate.protobuf.generated.StorageCluste" +
      "rStatus.Node\022\021\n\tdeadNodes\030\002 \003(\t\022\017\n\007regio" +
      "ns\030\003 \001(\005\022\020\n\010requests\030\004 \001(\005\022\023\n\013averageLoa" +
      "d\030\005 \001(\001\032J\n\004Node\022\014\n\004name\030\001 \002(\t\022\021\n\tstartCo" +
      "de\030\004 \001(\003\022\020\n\010requests\030\002 \001(\005\022\017\n\007regions\030\003 " +
      "\003(\014";
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_descriptor,
              new java.lang.String[] { "LiveNodes", "DeadNodes", "Regions", "Requests", "AverageLoad", },
              org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.class,
              org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Builder.class);
          internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_descriptor =
            internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_descriptor.getNestedTypes().get(0);
          internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_org_apache_hadoop_hbase_stargate_protobuf_generated_StorageClusterStatus_Node_descriptor,
              new java.lang.String[] { "Name", "StartCode", "Requests", "Regions", },
              org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.class,
              org.apache.hadoop.hbase.stargate.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus.Node.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }
}
